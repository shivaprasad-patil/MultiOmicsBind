{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bfd1e7",
   "metadata": {},
   "source": [
    "# üß¨ MultiOmicsBind: Complete Tutorial with Temporal Multi-Omics Integration\n",
    "\n",
    "This comprehensive notebook demonstrates all functionalities of **MultiOmicsBind**, including:\n",
    "\n",
    "- ‚úÖ Loading multi-omics data from CSV files\n",
    "- ‚úÖ Temporal multi-omics integration (time-series proteomics + static transcriptomics/cell painting)\n",
    "- ‚úÖ Automatic NaN detection and fixing\n",
    "- ‚úÖ Model training with binding modality\n",
    "- ‚úÖ Feature importance analysis\n",
    "- ‚úÖ Cross-modal similarity computation\n",
    "- ‚úÖ UMAP visualizations with **custom class names** (NEW!)\n",
    "- ‚úÖ **Dose-response analysis visualization** (NEW!)\n",
    "- ‚úÖ Modality contribution analysis\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "We'll work with:\n",
    "- **Transcriptomics** (6000 genes, baseline measurement)\n",
    "- **Cell Painting** (1500 features, baseline measurement)\n",
    "- **Proteomics** (4000 proteins, 5 timepoints: 0h, 1h, 2h, 4h, 8h)\n",
    "- **Metadata** (dose information and response labels)\n",
    "\n",
    "## Response Classes\n",
    "- **No Response** (Class 0): Low dose, minimal effect\n",
    "- **Partial Response** (Class 1): Medium dose, moderate effect\n",
    "- **Full Response** (Class 2): High dose, strong effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cc557",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20822fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# MultiOmicsBind imports\n",
    "from multiomicsbind.data.dataset import TemporalMultiOmicsDataset\n",
    "from multiomicsbind.core.model import MultiOmicsBindModel\n",
    "from multiomicsbind.training.trainer import train_temporal_model, evaluate_temporal_model\n",
    "from multiomicsbind.analysis import (\n",
    "    compute_feature_importance,\n",
    "    compute_cross_modal_similarity,\n",
    "    create_analysis_report\n",
    ")\n",
    "from multiomicsbind.utils.visualization import (\n",
    "    plot_training_history_detailed,\n",
    "    plot_cross_modal_similarity_matrices,\n",
    "    plot_embeddings_umap,\n",
    "    plot_dose_response_analysis  # NEW!\n",
    ")\n",
    "from multiomicsbind.utils.nan_handling import check_and_fix_all_nan_values\n",
    "\n",
    "# PyTorch utilities\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181087c",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load CSV Data Files\n",
    "\n",
    "First, let's check if the data files exist. If not, we'll generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data files exist\n",
    "data_files = {\n",
    "    'transcriptomics': 'transcriptomics_baseline.csv',\n",
    "    'cell_painting': 'cell_painting_baseline.csv',\n",
    "    'proteomics': 'proteomics_timeseries.csv',\n",
    "    'metadata': 'temporal_metadata.csv'\n",
    "}\n",
    "\n",
    "all_exist = all(os.path.exists(f) for f in data_files.values())\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"‚ö†Ô∏è Data files not found. Generating synthetic data...\")\n",
    "    print(\"(In production, you would load your own CSV files here)\")\n",
    "    \n",
    "    # Run data generation from temporal_example\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    exec(open('temporal_example.py').read())\n",
    "else:\n",
    "    print(\"‚úÖ All data files found!\")\n",
    "\n",
    "# List files with sizes\n",
    "for name, file in data_files.items():\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / 1024  # KB\n",
    "        print(f\"  {name:20s}: {file:40s} ({size:>8.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd5f96",
   "metadata": {},
   "source": [
    "### 2.1 Explore the Data Files\n",
    "\n",
    "Let's load and inspect each CSV file to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df800a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcriptomics data (static, baseline)\n",
    "transcriptomics_df = pd.read_csv('transcriptomics_baseline.csv')\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä TRANSCRIPTOMICS DATA (Baseline Gene Expression)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {transcriptomics_df.shape}\")\n",
    "print(f\"Columns: {list(transcriptomics_df.columns[:5])} ... (showing first 5)\")\n",
    "print(\"\\nFirst 3 samples:\")\n",
    "display(transcriptomics_df.head(3))\n",
    "\n",
    "# Load cell painting data (static, baseline)\n",
    "cell_painting_df = pd.read_csv('cell_painting_baseline.csv')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üî¨ CELL PAINTING DATA (Baseline Morphology Features)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {cell_painting_df.shape}\")\n",
    "print(f\"Columns: {list(cell_painting_df.columns[:5])} ... (showing first 5)\")\n",
    "print(\"\\nFirst 3 samples:\")\n",
    "display(cell_painting_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cc830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load proteomics time-series data (temporal)\n",
    "proteomics_df = pd.read_csv('proteomics_timeseries.csv')\n",
    "print(\"=\" * 80)\n",
    "print(\"‚è±Ô∏è  PROTEOMICS TIME-SERIES DATA (5 timepoints per sample)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {proteomics_df.shape}\")\n",
    "print(f\"Columns: {list(proteomics_df.columns[:5])} ... (showing first 5)\")\n",
    "print(\"\\nFirst 10 timepoints (2 samples √ó 5 timepoints):\")\n",
    "display(proteomics_df.head(10))\n",
    "\n",
    "# Check unique samples and timepoints\n",
    "print(f\"\\nUnique samples: {proteomics_df['sample_id'].nunique()}\")\n",
    "print(f\"Timepoints per sample: {proteomics_df.groupby('sample_id').size().unique()}\")\n",
    "print(f\"Timepoint values: {sorted(proteomics_df['timepoint'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ba2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata (includes dose and response labels)\n",
    "metadata_df = pd.read_csv('temporal_metadata.csv')\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã METADATA (Dose Information and Response Labels)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {list(metadata_df.columns)}\")\n",
    "print(\"\\nFirst 10 samples:\")\n",
    "display(metadata_df.head(10))\n",
    "\n",
    "# Analyze dose distribution by response class\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üíä DOSE-RESPONSE RELATIONSHIP\")\n",
    "print(\"=\" * 80)\n",
    "for response_class in sorted(metadata_df['response'].unique()):\n",
    "    class_data = metadata_df[metadata_df['response'] == response_class]\n",
    "    dose_mean = class_data['dose'].mean()\n",
    "    dose_std = class_data['dose'].std()\n",
    "    dose_range = (class_data['dose'].min(), class_data['dose'].max())\n",
    "    count = len(class_data)\n",
    "    print(f\"Class {response_class}: {count:3d} samples, \"\n",
    "          f\"dose = {dose_mean:.2f} ¬± {dose_std:.2f} ŒºM, \"\n",
    "          f\"range [{dose_range[0]:.2f}-{dose_range[1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522a418",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Create Temporal Multi-Omics Dataset\n",
    "\n",
    "Now let's create the MultiOmicsBind dataset that integrates all modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TemporalMultiOmicsDataset\n",
    "print(\"Creating temporal multi-omics dataset...\")\n",
    "\n",
    "dataset = TemporalMultiOmicsDataset(\n",
    "    static_files={\n",
    "        'transcriptomics': 'transcriptomics_baseline.csv',\n",
    "        'cell_painting': 'cell_painting_baseline.csv'\n",
    "    },\n",
    "    temporal_files={\n",
    "        'proteomics': 'proteomics_timeseries.csv'\n",
    "    },\n",
    "    metadata_file='temporal_metadata.csv',\n",
    "    label_col='response',\n",
    "    num_cols=['dose'],  # Include dose as numerical metadata\n",
    "    cat_cols=['treatment_day']  # Categorical metadata\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset created successfully!\")\n",
    "print(f\"   Total samples: {len(dataset)}\")\n",
    "print(f\"   Static modalities: {dataset.static_modalities}\")\n",
    "print(f\"   Temporal modalities: {dataset.temporal_modalities}\")\n",
    "print(f\"   Number of classes: {len(dataset.get_labels().unique())}\")\n",
    "\n",
    "# Get a sample to check structure\n",
    "sample = dataset[0]\n",
    "print(f\"\\nüì¶ Sample structure:\")\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"   {key:20s}: shape {tuple(value.shape)}, dtype {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"   {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdf9b9",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Automatic NaN Detection and Fixing\n",
    "\n",
    "MultiOmicsBind includes automatic NaN detection and fixing for all modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fix NaN values across all modalities\n",
    "print(\"üîç Checking for NaN values in all modalities...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "check_and_fix_all_nan_values(dataset, verbose=True)\n",
    "\n",
    "print(\"\\n‚úÖ Dataset is now clean and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f0cf5",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Train/Test Split\n",
    "\n",
    "Split data properly to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train (70%) and test (30%)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset split:\")\n",
    "print(f\"   Training samples: {len(train_dataset)} ({len(train_dataset)/len(dataset)*100:.1f}%)\")\n",
    "print(f\"   Test samples: {len(test_dataset)} ({len(test_dataset)/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "# Verify no overlap\n",
    "train_indices = set(train_dataset.indices)\n",
    "test_indices = set(test_dataset.indices)\n",
    "overlap = train_indices & test_indices\n",
    "print(f\"\\nüîí Data leakage check: {len(overlap)} overlapping samples (should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6d293",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Model Training\n",
    "\n",
    "Train the MultiOmicsBind model with binding modality approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61334523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using high-level API\n",
    "print(\"üöÄ Training MultiOmicsBind model...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model, history = train_temporal_model(\n",
    "    dataset=train_dataset,\n",
    "    device=device,\n",
    "    n_classes=3,  # No Response, Partial Response, Full Response\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    dropout=0.1,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    save_path='multiomicsbind_model.pth',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Final training accuracy: {history['train_acc'][-1]:.4f}\")\n",
    "print(f\"   Model saved to: multiomicsbind_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfca64f",
   "metadata": {},
   "source": [
    "### 6.1 Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history_detailed(history, save_path='training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history plot saved to 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7579d",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Model Evaluation on Test Set\n",
    "\n",
    "Evaluate the trained model on held-out test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating model on test set...\")\n",
    "embeddings, labels, predictions = evaluate_temporal_model(model, test_dataset, device)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = (predictions == labels).mean()\n",
    "print(f\"\\n‚úÖ Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Show per-class accuracy\n",
    "for class_idx in range(3):\n",
    "    class_mask = labels == class_idx\n",
    "    if class_mask.sum() > 0:\n",
    "        class_acc = (predictions[class_mask] == labels[class_mask]).mean()\n",
    "        print(f\"   Class {class_idx} accuracy: {class_acc:.4f} ({class_mask.sum()} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e7134",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Feature Importance Analysis\n",
    "\n",
    "Compute which features contribute most to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbeef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature importance using gradients\n",
    "print(\"üîç Computing feature importance...\")\n",
    "importance_dict, importance_df = compute_feature_importance(\n",
    "    model, dataset, device, n_batches=10, verbose=True\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "importance_df.to_csv('feature_importance.csv', index=False)\n",
    "print(\"\\n‚úÖ Feature importance saved to 'feature_importance.csv'\")\n",
    "\n",
    "# Display top features per modality\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 5 FEATURES PER MODALITY\")\n",
    "print(\"=\" * 80)\n",
    "for modality in importance_df['modality'].unique():\n",
    "    modality_df = importance_df[importance_df['modality'] == modality]\n",
    "    top_features = modality_df.nlargest(5, 'importance')\n",
    "    print(f\"\\n{modality.upper()}:\")\n",
    "    for idx, row in top_features.iterrows():\n",
    "        print(f\"  {row['feature_name']:30s}: {row['importance']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae17abc",
   "metadata": {},
   "source": [
    "### 8.1 Modality Contribution Analysis\n",
    "\n",
    "Analyze how much each modality contributes to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b147f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate contribution by modality\n",
    "modality_contribution = importance_df.groupby('modality')['importance'].sum().sort_values(ascending=False)\n",
    "total_importance = modality_contribution.sum()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODALITY CONTRIBUTION TO PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "modality_pct = (modality_contribution / total_importance * 100)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(modality_pct)))\n",
    "ax1.bar(range(len(modality_pct)), modality_pct, color=colors)\n",
    "ax1.set_xticks(range(len(modality_pct)))\n",
    "ax1.set_xticklabels(modality_pct.index, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Contribution (%)', fontsize=12)\n",
    "ax1.set_title('Modality Contribution to Predictions', fontsize=13, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(modality_pct, labels=modality_pct.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax2.set_title('Modality Distribution', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modality_contribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "for modality, importance in modality_contribution.items():\n",
    "    pct = (importance / total_importance) * 100\n",
    "    print(f\"  {modality:20s}: {pct:>6.2f}% ({importance:.4f})\")\n",
    "\n",
    "# Temporal vs static analysis\n",
    "if 'proteomics' in modality_contribution.index:\n",
    "    proteomics_pct = (modality_contribution['proteomics'] / total_importance) * 100\n",
    "    print(f\"\\n{'‚úì' if proteomics_pct > 50 else '‚Üí'} Temporal proteomics: {proteomics_pct:.1f}%\")\n",
    "    if proteomics_pct > 60:\n",
    "        print(\"  ‚Üí Temporal dynamics are highly informative\")\n",
    "    elif proteomics_pct < 40:\n",
    "        print(\"  ‚Üí Baseline state more predictive than dynamics\")\n",
    "    else:\n",
    "        print(\"  ‚Üí Balanced temporal and static contributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec97da",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Cross-Modal Similarity Analysis\n",
    "\n",
    "Measure how similar embeddings are across different modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-modal similarity\n",
    "print(\"üîó Computing cross-modal similarity...\")\n",
    "similarity_dict = compute_cross_modal_similarity(model, dataset, device)\n",
    "\n",
    "# Visualize similarity matrices\n",
    "plot_cross_modal_similarity_matrices(similarity_dict, save_path='similarity_matrices.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Cross-modal similarity matrices saved to 'similarity_matrices.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0494c61",
   "metadata": {},
   "source": [
    "## üîü Comprehensive Analysis Report with Class Names (NEW!)\n",
    "\n",
    "Generate a complete analysis report with **custom class names** appearing in all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define meaningful class names\n",
    "class_names = ['No Response', 'Partial Response', 'Full Response']\n",
    "\n",
    "print(\"üìä Generating comprehensive analysis report with custom class names...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Generate report on TEST SET only (prevents data leakage!)\n",
    "report = create_analysis_report(\n",
    "    model=model,\n",
    "    dataset=test_dataset,  # ‚Üê Use test set!\n",
    "    device=device,\n",
    "    class_names=class_names,  # ‚Üê Custom class names!\n",
    "    output_dir='./analysis_results',\n",
    "    compute_importance=True,\n",
    "    compute_similarity=True,\n",
    "    n_importance_batches=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTest Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"Output directory: analysis_results/\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ classification_report.txt\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ confusion_matrix.png\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ embeddings_umap_transcriptomics.png (with class names!)\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ embeddings_umap_cell_painting.png (with class names!)\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ embeddings_umap_proteomics.png (with class names!)\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ feature_importance.csv\")\n",
    "print(\"  ‚îî‚îÄ‚îÄ cross_modal_similarity.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48729f05",
   "metadata": {},
   "source": [
    "### 10.1 View UMAP Visualizations with Class Names\n",
    "\n",
    "Let's display the UMAP plots showing our custom class names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display UMAP plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"UMAP Visualizations (showing class names, not 'Class 0, 1, 2'):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "modalities = ['transcriptomics', 'cell_painting', 'proteomics']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, modality in enumerate(modalities):\n",
    "    img_path = f'analysis_results/embeddings_umap_{modality}.png'\n",
    "    if os.path.exists(img_path):\n",
    "        img = plt.imread(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'{modality.capitalize()}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ All UMAPs show 'No Response', 'Partial Response', 'Full Response'!\")\n",
    "print(\"   (Not generic 'Class 0', 'Class 1', 'Class 2')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c0e92",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Dose-Response Visualization (NEW! üéâ)\n",
    "\n",
    "Analyze how **dose** contributes to predictions with a comprehensive 3-panel visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and extract test set doses\n",
    "metadata = pd.read_csv('temporal_metadata.csv')\n",
    "test_metadata = metadata.iloc[test_dataset.indices].reset_index(drop=True)\n",
    "\n",
    "# Get test set predictions and labels\n",
    "test_labels = report['labels']\n",
    "test_predictions = report['predictions']\n",
    "test_doses = test_metadata['dose'].values\n",
    "\n",
    "print(\"üíä DOSE-RESPONSE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show dose statistics by class\n",
    "print(\"\\nDose distribution by TRUE response class:\")\n",
    "for class_idx in range(3):\n",
    "    mask = test_labels == class_idx\n",
    "    if mask.sum() > 0:\n",
    "        doses = test_doses[mask]\n",
    "        print(f\"  {class_names[class_idx]:20s}: \"\n",
    "              f\"mean={doses.mean():.2f} ŒºM, \"\n",
    "              f\"median={np.median(doses):.2f} ŒºM, \"\n",
    "              f\"range=[{doses.min():.2f}-{doses.max():.2f}]\")\n",
    "\n",
    "print(\"\\nDose distribution by PREDICTED response class:\")\n",
    "for class_idx in range(3):\n",
    "    mask = test_predictions == class_idx\n",
    "    if mask.sum() > 0:\n",
    "        doses = test_doses[mask]\n",
    "        print(f\"  {class_names[class_idx]:20s}: \"\n",
    "              f\"mean={doses.mean():.2f} ŒºM, \"\n",
    "              f\"median={np.median(doses):.2f} ŒºM, \"\n",
    "              f\"range=[{doses.min():.2f}-{doses.max():.2f}]\")\n",
    "\n",
    "print(\"\\n‚úì Model learned dose-response relationship!\")\n",
    "print(\"  ‚Üí Higher doses generally lead to stronger responses\")\n",
    "print(\"  ‚Üí Dose treated as continuous numerical metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f1239",
   "metadata": {},
   "source": [
    "### 11.1 Generate 3-Panel Dose-Response Visualization\n",
    "\n",
    "This NEW function creates a comprehensive visualization showing:\n",
    "1. **Dose distribution by class** (violin plots)\n",
    "2. **Dose vs predictions** (scatter plot with accuracy markers)\n",
    "3. **Mean dose comparison** (true vs predicted classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabe7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dose-response visualization\n",
    "print(\"\\nüìä Generating dose-response visualization...\")\n",
    "\n",
    "plot_dose_response_analysis(\n",
    "    doses=test_doses,\n",
    "    labels=test_labels,\n",
    "    predictions=test_predictions,\n",
    "    class_names=class_names,\n",
    "    save_path='dose_response_analysis.png'\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dose-response analysis saved to 'dose_response_analysis.png'\")\n",
    "print(\"\\nThis plot shows:\")\n",
    "print(\"  1. Left panel: Dose distribution by true class (violin plots)\")\n",
    "print(\"  2. Center panel: Dose vs predictions (circles=correct, X=incorrect)\")\n",
    "print(\"  3. Right panel: Mean dose per class (blue=true, coral=predicted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b90f71",
   "metadata": {},
   "source": [
    "### 11.2 Sample Predictions with Dose Information\n",
    "\n",
    "Let's look at some example predictions with dose values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with predictions and doses\n",
    "results_df = pd.DataFrame({\n",
    "    'sample_id': test_metadata['sample_id'].values[:10],\n",
    "    'dose_ŒºM': test_doses[:10],\n",
    "    'true_class': [class_names[i] for i in test_labels[:10]],\n",
    "    'predicted_class': [class_names[i] for i in test_predictions[:10]],\n",
    "    'correct': ['‚úì' if test_labels[i] == test_predictions[i] else '‚úó' \n",
    "                for i in range(10)]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE PREDICTIONS WITH DOSE INFORMATION (First 10 Test Samples)\")\n",
    "print(\"=\" * 80)\n",
    "display(results_df)\n",
    "\n",
    "# Calculate overall accuracy by dose range\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ACCURACY BY DOSE RANGE\")\n",
    "print(\"=\" * 80)\n",
    "dose_ranges = [(0, 3), (3, 6), (6, 10)]\n",
    "for low, high in dose_ranges:\n",
    "    mask = (test_doses >= low) & (test_doses < high)\n",
    "    if mask.sum() > 0:\n",
    "        accuracy = (test_predictions[mask] == test_labels[mask]).mean()\n",
    "        n_samples = mask.sum()\n",
    "        print(f\"  {low}-{high} ŒºM: {accuracy:.3f} accuracy ({n_samples} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a021f2",
   "metadata": {},
   "source": [
    "## üéØ Summary and Key Findings\n",
    "\n",
    "Let's summarize all the analyses we performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üéØ MULTIOMICSBIND COMPLETE TUTORIAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä MODEL PERFORMANCE:\")\n",
    "print(f\"  ‚Ä¢ Test Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Training samples: {len(train_dataset)}\")\n",
    "print(f\"  ‚Ä¢ Test samples: {len(test_dataset)}\")\n",
    "print(f\"  ‚Ä¢ No data leakage: Train and test sets completely separate\")\n",
    "\n",
    "print(\"\\nüß¨ DATA INTEGRATION:\")\n",
    "print(f\"  ‚Ä¢ Successfully integrated 3 modalities:\")\n",
    "print(f\"    - Transcriptomics: 6000 genes (static baseline)\")\n",
    "print(f\"    - Cell Painting: 1500 features (static baseline)\")\n",
    "print(f\"    - Proteomics: 4000 proteins √ó 5 timepoints (temporal)\")\n",
    "print(f\"  ‚Ä¢ Metadata: dose + treatment_day\")\n",
    "print(f\"  ‚Ä¢ Total samples: {len(dataset)}\")\n",
    "\n",
    "print(\"\\n‚ú® NEW FEATURES DEMONSTRATED:\")\n",
    "print(\"  ‚úÖ Custom class names in all visualizations\")\n",
    "print(\"     ('No Response', 'Partial Response', 'Full Response')\")\n",
    "print(\"     instead of generic 'Class 0', 'Class 1', 'Class 2'\")\n",
    "print(\"\\n  ‚úÖ Dose-response visualization (3-panel plot)\")\n",
    "print(\"     - Dose distribution by class (violin plots)\")\n",
    "print(\"     - Dose vs predictions with accuracy markers\")\n",
    "print(\"     - Mean dose comparison (true vs predicted)\")\n",
    "print(\"\\n  ‚úÖ Modality contribution analysis\")\n",
    "print(\"     - Percentage contribution of each modality\")\n",
    "print(\"     - Temporal vs static comparison\")\n",
    "print(\"\\n  ‚úÖ Automatic NaN detection and fixing\")\n",
    "print(\"     - Scans all modalities for missing values\")\n",
    "print(\"     - Intelligent filling strategies\")\n",
    "\n",
    "print(\"\\nüìÅ GENERATED FILES:\")\n",
    "files = [\n",
    "    'multiomicsbind_model.pth',\n",
    "    'training_history.png',\n",
    "    'feature_importance.csv',\n",
    "    'modality_contribution.png',\n",
    "    'similarity_matrices.png',\n",
    "    'dose_response_analysis.png',\n",
    "    'analysis_results/classification_report.txt',\n",
    "    'analysis_results/confusion_matrix.png',\n",
    "    'analysis_results/embeddings_umap_*.png (with class names!)',\n",
    "    'analysis_results/cross_modal_similarity.png'\n",
    "]\n",
    "for i, file in enumerate(files, 1):\n",
    "    print(f\"  {i:2d}. {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ TUTORIAL COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nYou've learned how to:\")\n",
    "print(\"  1. Load multi-omics data from CSV files\")\n",
    "print(\"  2. Create temporal multi-omics datasets\")\n",
    "print(\"  3. Handle NaN values automatically\")\n",
    "print(\"  4. Train MultiOmicsBind models with binding modality\")\n",
    "print(\"  5. Evaluate on held-out test sets (no data leakage)\")\n",
    "print(\"  6. Compute feature importance\")\n",
    "print(\"  7. Analyze cross-modal similarity\")\n",
    "print(\"  8. Generate UMAPs with custom class names\")\n",
    "print(\"  9. Visualize dose-response relationships\")\n",
    "print(\" 10. Analyze modality contributions\")\n",
    "print(\"\\nüí° Next steps:\")\n",
    "print(\"  ‚Ä¢ Try with your own multi-omics data!\")\n",
    "print(\"  ‚Ä¢ Experiment with different architectures\")\n",
    "print(\"  ‚Ä¢ Explore advanced features in the documentation\")\n",
    "print(\"  ‚Ä¢ Check DOSE_RESPONSE_VISUALIZATION.md for detailed guide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6e497",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "For more information, check out:\n",
    "\n",
    "### Documentation\n",
    "- **[README.md](../README.md)** - Overview and getting started\n",
    "- **[ADVANCED_USAGE_GUIDE.md](../ADVANCED_USAGE_GUIDE.md)** - Advanced features and patterns\n",
    "- **[QUICK_ANSWERS.md](../QUICK_ANSWERS.md)** - Quick reference for common questions\n",
    "- **[DOSE_RESPONSE_VISUALIZATION.md](../DOSE_RESPONSE_VISUALIZATION.md)** - Detailed dose-response guide\n",
    "\n",
    "### Examples\n",
    "- **[basic_example.py](basic_example.py)** - Simple multi-omics integration\n",
    "- **[temporal_example.py](temporal_example.py)** - Temporal multi-omics (source for this notebook)\n",
    "- **[flexible_modalities_example.py](flexible_modalities_example.py)** - Flexible modality combinations\n",
    "\n",
    "### Key Concepts\n",
    "- **Binding Modality**: Efficient attention mechanism for multi-omics integration\n",
    "- **Temporal Integration**: LSTM-based encoding for time-series omics data\n",
    "- **Cross-Modal Learning**: Learning unified representations across modalities\n",
    "- **Gradient-Based Importance**: Feature importance via gradient attribution\n",
    "\n",
    "### Citation\n",
    "If you use MultiOmicsBind in your research, please cite:\n",
    "\n",
    "```bibtex\n",
    "@software{multiomicsbind2024,\n",
    "  author = {Shivaprasad Patil},\n",
    "  title = {MultiOmicsBind: Integrative Multi-Omics Analysis with Binding Modality},\n",
    "  year = {2024},\n",
    "  url = {https://github.com/shivaprasad-patil/MultiOmicsBind}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/shivaprasad-patil/MultiOmicsBind\n",
    "\n",
    "**Questions or Issues?** Open an issue on GitHub!\n",
    "\n",
    "---\n",
    "\n",
    "Thank you for using MultiOmicsBind! üß¨‚ú®"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
